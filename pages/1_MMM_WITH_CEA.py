import pandas as pd
import streamlit as st
# Plotting the graph
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm

import numpy as np

from scipy.optimize import linprog
import math

st.set_page_config(
    page_title="Report Assistant_MMM",
    page_icon="ğŸ¥‡",
    layout="wide",
)

import insert_logo 
insert_logo.add_logo("withbrother_logo.png")

# Find a font that supports Hangul (Korean)
font_path = "static/NanumGothic-Regular.ttf"
fontprop = fm.FontProperties(fname=font_path)

# Applying the font
plt.rcParams['font.family'] = fontprop.get_name()
# The user hasn't provided the dataframe itself, only a screenshot of the headers. 
# I'll create a sample dataframe based on the visible column names to proceed with plotting.

def calculate_icer_with_mc(df, min_cost, effect_columns):
    icers = pd.DataFrame()
    icers['Incr Cost'] = df['ëˆ„ì ë¹„ìš©'] - min_cost
    for effect_col in effect_columns:
        df[effect_col] = df[effect_col].round(0)
        min_effect = df.loc[df['ëˆ„ì ë¹„ìš©'] == min_cost, effect_col].values[0]
        icers['Incr Eff' + effect_col.split("_")[-1]] = df[effect_col] - min_effect

        # 5. ICER ê³„ì‚° (ë¹„ìš© ì°¨ì´ë¥¼ íš¨ê³¼ ì°¨ì´ë¡œ ë‚˜ëˆˆ ê°’)
        icers['ICER' + effect_col.split("_")[-1]] = icers['Incr Cost'] / icers['Incr Eff' + effect_col.split("_")[-1]]
    return icers

def calculate_ceac(icer_list, wtp):
    return [np.mean([((0 < icer) and (icer <= threshold)) for icer in icer_list]) for threshold in wtp]

# íŠ¹ì • WTPì—ì„œ CEAC ê°’ì„ ë…¸ë©€ë¼ì´ì¦ˆí•˜ëŠ” í•¨ìˆ˜
def normalize_ceac_by_wtp(ceac_values_per_media):
    # Transpose the CEAC values so that each WTP has values across all media
    ceac_values_per_media = np.array(ceac_values_per_media).T
    
    # WTPë³„ë¡œ í•©ì„ êµ¬í•˜ê³  ë…¸ë©€ë¼ì´ì¦ˆ
    normalized_ceac = []
    for ceac_values_at_wtp in ceac_values_per_media:
        summed_value = np.sum(ceac_values_at_wtp)
        if summed_value > 0:
            normalized_ceac.append(ceac_values_at_wtp / summed_value)
        else:
            normalized_ceac.append(np.zeros_like(ceac_values_at_wtp))
    
    return np.array(normalized_ceac).T  # ë‹¤ì‹œ Transposeí•˜ì—¬ ì›ë˜ í˜•íƒœë¡œ ë°˜í™˜

#ë³´ê³ ì„œ ìœ í˜• ì €ì¥
if 'ider_df' not in st.session_state:
    st.session_state.icer_df = None

#ë³´ê³ ì„œ ìœ í˜• ì €ì¥
if 'org_df' not in st.session_state:
    st.session_state.org_df = None

#ê¸°ê°„ ì €ì¥
if 'ceac' not in st.session_state:
    st.session_state.ceac = None


st.title('ê´‘ê³  ì˜ˆì‚° íš¨ìœ¨ ë° ì¶”ì²œ(MMM)')


# ë°ì´í„° ì…ë ¥ê¸°
with st.sidebar: #ì›í•˜ëŠ” ì†ŒìŠ¤ë¥¼ ë§Œë“œëŠ” ê³³
    st.sidebar.header('ì´ê³³ì— ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.')
    
    data = st.file_uploader(
        "ë§¤ì²´ ë°ì´í„° ì—…ë¡œë“œ (Excel or CSV)",
        type=['xls','xlsx', 'csv'],
        key="uploader1"
    )

if data:
    st.header("1. ICER ë¶„ì„")
    st.write("ìµœì € ë¹„ìš©ì˜ ë§¤ì²´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¹„ìš© íš¨ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. (ICER : Incremental Cost Effectiveness Ratio)")
    with st.spinner("ë¶„ì„ ì¤‘"):

        if st.session_state.icer_df is None:
            data1 = pd.read_excel('ë…¸ìŠ¤í˜ì´ìŠ¤_ë°ëª¨_ë°ì´í„°_v3.xlsx')
            df = pd.DataFrame(data1)

            df['ì¼ì'] = pd.to_datetime(df['ì¼ì'])

            filtered_df = df[df['ì¼ì'] == pd.to_datetime('2024-07-31')]
                # 2. ì´ë¹„ìš©ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            df_sorted = filtered_df.sort_values('ëˆ„ì ë¹„ìš©')

            # 3. ì´ë¹„ìš©ì´ ê°€ì¥ ë‚®ì€ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì°¨ì´ë¥¼ ê³„ì‚°
            min_cost = df_sorted['ëˆ„ì ë¹„ìš©'].min()
            df_sorted['Incr Cost'] = df_sorted['ëˆ„ì ë¹„ìš©'] - min_cost

            # 4. íš¨ê³¼ ì°¨ì´ ê³„ì‚°
            df_sorted['íš¨ê³¼'] = df_sorted['íš¨ê³¼'].round(0)
            min_effect = df_sorted.loc[df_sorted['ëˆ„ì ë¹„ìš©'] == min_cost, 'íš¨ê³¼'].values[0]
            df_sorted['Incr Eff'] = df_sorted['íš¨ê³¼'] - min_effect

            # 5. ICER ê³„ì‚° (ë¹„ìš© ì°¨ì´ë¥¼ íš¨ê³¼ ì°¨ì´ë¡œ ë‚˜ëˆˆ ê°’)
            df_sorted['ICER'] = (df_sorted['Incr Cost'] / df_sorted['Incr Eff']).round(1)
            df_sorted['ë§¤ì¶œ'] = df_sorted['ëˆ„ì êµ¬ë§¤ì•¡']

            # Calculate the proportion of each value relative to the total sales
            df_sorted['ë§¤ì¶œ ë¹„ì¤‘'] = ((df_sorted['ëˆ„ì êµ¬ë§¤ì•¡']/df_sorted['ëˆ„ì êµ¬ë§¤ì•¡'].sum())*100).round(2)

            df_final = df_sorted[['ë§¤ì²´', 'ëˆ„ì ë¹„ìš©', 'Incr Cost', 'íš¨ê³¼', 'Incr Eff', 'ICER', 'ë§¤ì¶œ', 'ë§¤ì¶œ ë¹„ì¤‘']]
            st.session_state.icer_df = df_final
            st.session_state.org_df = df
            st.write(df_final)
        else:
            df_final = st.session_state.icer_df
            df = st.session_state.org_df
            st.write(st.session_state.icer_df)
    
    with st.expander("See Terminologies"):
        st.write(
            '''
            COST : í•´ë‹¹ ê¸°ê°„ì— íˆ¬ì…í•œ ë¹„ìš© \n
            Incr cost : ê°€ì¥ ë¹„ìš©ì´ ì ê²Œ íˆ¬ì…í•œ ê´‘ê³  ë§¤ì²´ì˜ ë¹„ìš©ê³¼ì˜ ë¹„ìš© ì°¨ì´ \n
            Eff : ê´‘ê³  ë…¸ì¶œì´ 1ë˜ì—ˆì„ ë•Œ, ì–»ì„ ìˆ˜ ìˆëŠ” ê¸ˆì•¡ íš¨ìœ¨ \n
            Incr Eff : ê°€ì¥ ë¹„ìš©ì´ ì ê²Œ íˆ¬ì…í•œ ê´‘ê³  ë§¤ì²´ì˜ íš¨ê³¼ì™€ì˜ íš¨ê³¼ ì°¨ì´ \n
            ICER : íš¨ê³¼ 1ì„ ì˜¬ë¦¬ê¸° ìœ„í•œ í•„ìš” ë¹„ìš© (ìŒìˆ˜ì¼ ê²½ìš°, ìƒëŒ€ì  íš¨ê³¼ê°€ ì—†ë‹¤ê³  í•´ì„)
            '''
        )

    st.write(
        '''
        - í‹±í†¡ì— ê°€ì¥ ë¹„ìš©ì„ ì ê²Œ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
        - í‹±í†¡ê³¼ ëŒ€ë¹„í•˜ì—¬ êµ¬ê¸€ ê²€ìƒ‰ê´‘ê³ , ë©”íƒ€ê°€ ìœ ì˜ë¯¸í•œ íš¨ê³¼ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.
        - êµ¬ê¸€ ê²€ìƒ‰ê´‘ê³ ëŠ” í‹±í†¡ì— ë¹„í•´ 1ì˜ íš¨ê³¼ë¥¼ ë†’ì´ê¸° ìœ„í•´ 9.1 ì˜ ë¹„ìš©ì´ ë” í•„ìš”í•©ë‹ˆë‹¤.
        - ë©”íƒ€ëŠ” 6.1ì˜ ë¹„ìš©ì´ ë” í•„ìš”í•©ë‹ˆë‹¤.
        - ë©”íƒ€ê°€ ë¹„íš¨ìœ¨ì ì¸ ê²ƒì´ ì•„ë‹ˆëƒë¼ê³  ë°˜ë¬¸í•  ìˆ˜ ìˆìœ¼ë‚˜, ë©”íƒ€ê°€ ë§¤ì¶œì˜ êµ‰ì¥íˆ ë§ì€ ë¹„ìœ¨(55.53%)ì„ ì°¨ì§€í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ë¹„íš¨ìœ¨ì ì´ì§€ë§Œ ì•ˆì •ì ì¸ ë§¤ì¶œì„ ì„ íƒí•  ê²ƒì¸ì§€ì— ëŒ€í•œ ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
        - í‹±í†¡ì— ëŒ€ë¹„í•˜ì—¬ êµ¬ê¸€ê²€ìƒ‰ê´‘ê³ ëŠ” íš¨ê³¼ 1ì› ì˜¬ë¦¬ëŠ”ë°9.1ì› ë” ë“¤ê³ , ë©”íƒ€ëŠ” í‹±í†¡ë³´ë‹¤ íš¨ê³¼ 1ì› ì˜¬ë¦¬ëŠ”ê²Œ 6.1ì› ë” ë“­ë‹ˆë‹¤. ê·¸ë ‡ê¸°ì— í‹±í†¡ì´ êµ¬ê¸€ì´ë‚˜ ë©”íƒ€ë³´ë‹¤ íš¨ìœ¨ì´ ë–¨ì–´ì§€ëŠ” ìƒíƒœëŠ” ì•„ë‹™ë‹ˆë‹¤.
        '''
    )

    st.header("2. ë¹„ìš©-íš¨ê³¼ ì¶”ì„¸ ë¶„ì„ ê·¸ë˜í”„")

    st.write('ë¹„ìš© ì¦ê°€ì— ë”°ë¥¸ íš¨ìœ¨ ì¶”ì„¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.')

    plt.figure(figsize=(10, 6))
    sns.lineplot(data=df, x="ëˆ„ì ë¹„ìš©", y="íš¨ê³¼", hue="ë§¤ì²´", marker="o", dashes=False)

    plt.title("Effectiveness by Total Cost and Media")
    plt.xlabel("Total Cost (ëˆ„ì ë¹„ìš©)")
    plt.ylabel("Effectiveness (íš¨ê³¼)")
    plt.grid(True)
    # Display plot in Streamlit
    st.pyplot(plt)

    st.write(
        '''
        - í‹±í†¡ì€ ì„±ê³¼ ìì²´ê°€ ë¹„êµì  í¬ì§€ëŠ” ì•Šìœ¼ë‚˜, ë¹„ìš© ëŒ€ë¹„ ê¾¸ì¤€í•œ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. (ì„ í˜•ì˜ ë³€í™”ê°€ ìœ ì§€ë¨)
        - í‹±í†¡ì˜ ì˜ˆì‚°ì„ ì¢€ë” ì¶”ê°€í•´ë³´ëŠ” ê²ƒì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        - êµ¬ê¸€ ê²€ìƒ‰ ê´‘ê³ ëŠ” 2ë°±ë§Œì›ê¹Œì§€ íš¨ìœ¨ì´ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•˜ë‹¤, ì´í›„ë¡œ íš¨ìœ¨ì´ ê¸‰ê²©íˆ ë–¨ì–´ì§€ëŠ” ëª¨ìŠµì…ë‹ˆë‹¤.
        - ì˜ˆì‚° ì§‘í–‰ ì¤‘ì§€ ì‹œì ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        - ë©”íƒ€ëŠ” ì ì°¨ íš¨ìœ¨ ìƒìŠ¹ì˜ í¬í™”ê°€ ì´ë£¨ì§€ëŠ” ì–‘ìƒì…ë‹ˆë‹¤.
        - ì €ë¹„ìš©-ê³ íš¨ìœ¨ ì „ëµì„ ìˆ˜ë¦½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        '''
    )


    st.header("3. í™•ë¥ ë¡ ì  ë¯¼ê°ë„ë¶„ì„ ë° ë¹„ìš©-íš¨ê³¼ ìŠ¹ì¸ ì»¤ë¸Œ ë¶„ì„")
    st.write('íš¨ê³¼ 1ì„ ì–»ê¸° ìœ„í•œ ë¹„ìš© ì§€ë¶ˆì˜ì‚¬ë³„ ë§¤ì²´ ë¯¹ìŠ¤ íš¨ìœ¨ì„± í™•ë¥ ì„ ë¶„ì„í•©ë‹ˆë‹¤.')

    if st.session_state.ceac is None:
        # Load the probability data
        df_prob = pd.read_excel("ë…¸ìŠ¤í˜ì´ìŠ¤_ë§¤ì²´ë³„_í™•ë¥ _í•„í„°ë§_v2.xlsx")

        # Step 1: Simulate random probabilities for pClick and pPurchase for 10,000 times for each media

        n_simulations = 100

        random_effects = pd.DataFrame()

        for i, row in df_prob.iterrows():
            # Generate random probabilities for pClick and pPurchase
            random_pClick = np.random.normal(row['pClick_mean'], row['pClick_std'], n_simulations)
            random_pPurchase = np.random.normal(row['pPurchase_mean'], row['pPurchase_std'], n_simulations)
            
            # Calculate the effect by multiplying the random probabilities with the 'ëˆ„ì êµ¬ë§¤ì•¡'
            effect = random_pClick * random_pPurchase * row['ëˆ„ì êµ¬ë§¤ì•¡']
            
            # Store the effect values in the random_effects DataFrame
            random_effects[f'effect_{row["ë§¤ì²´"]}'] = effect

        
        effect_pivot_df = random_effects.T
        # Renaming columns to "íš¨ê³¼_0", "íš¨ê³¼_1", etc.
        effect_pivot_df.columns = [f'íš¨ê³¼_{i}' for i in range(effect_pivot_df.shape[1])]
        effect_pivot_df.index = effect_pivot_df.index.str.replace('effect_', '')

        # Step 4: Merge the pivoted effect data with media_df based on the media names
        final_merged_df = pd.merge(df_prob, effect_pivot_df, left_on='ë§¤ì²´', right_index=True)
        # Step 2: Calculate ICER by comparing the costs and effects
        df_sorted_prob = final_merged_df.sort_values('ëˆ„ì ë¹„ìš©')
        min_cost = df_sorted_prob['ëˆ„ì ë¹„ìš©'].min()

        #st.write(df_sorted_prob)

        effect_columns = [col for col in df_sorted_prob.columns if 'íš¨ê³¼' in col]

        # Calculating ICER using the minimum cost reference
        icer_df = calculate_icer_with_mc(df_sorted_prob, min_cost, effect_columns)

        # Adding an index column for readability
        icer_df.index = df_sorted_prob['ë§¤ì²´']

        #st.write(icer_df)

        # Define WTP thresholds (these can be adjusted)
        wtp_thresholds = np.arange(0, 100, 1)
        # Extracting only the ICER columns (which typically have names starting with 'ICER')
        icer_columns = [col for col in icer_df.columns if 'ICER' in col]

        # Create a dictionary of media and their corresponding ICER values
        icer_values = {media_name: row[icer_columns].values for media_name, row in icer_df.iterrows()}
        icer_values["í‹±í†¡"] = np.ones_like(icer_values["ë©”íƒ€"])

        
        # Create CEAC plot
        plt.figure(figsize=(10, 6))

        # ê° ë¯¸ë””ì–´ë³„ë¡œ WTPì— ë”°ë¥¸ CEAC ê³„ì‚°
        ceac_values_per_media = []
        for media, icer_list in icer_values.items():
            ceac_values_per_media.append(calculate_ceac(icer_list, wtp_thresholds))

        # ê° WTPì— ëŒ€í•œ CEAC ê°’ì„ ë…¸ë©€ë¼ì´ì¦ˆ
        normalized_ceac_values_per_wtp = normalize_ceac_by_wtp(ceac_values_per_media)

        extracted_probabilities = {}
        wtp_thresholds_list = wtp_thresholds.tolist()
        wtp = 10
        # ë¯¸ë””ì–´ë³„ë¡œ ë…¸ë©€ë¼ì´ì¦ˆëœ CEAC ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        for i, media in enumerate(icer_values.keys()):
            wtp_index = wtp_thresholds_list.index(wtp)
            extracted_probabilities[media] = normalized_ceac_values_per_wtp[i][wtp_index]
            plt.plot(wtp_thresholds, normalized_ceac_values_per_wtp[i], label=f'{media} (Normalized CEAC)')


        # Customize plot with additional information
        plt.title('CE Acceptability Curve')
        plt.xlabel('Willingness-to-Pay')
        plt.ylabel('% Iterations Cost-Effective')
        plt.legend(title="Strategy", loc='best', bbox_to_anchor=(1.05, 1))
        plt.grid(True)

        plt.tight_layout()
        st.pyplot(plt)
        
        st.session_state.ceac = {}
        st.session_state.ceac['icer_values'] = icer_values
        st.session_state.ceac['wtp_thresholds_list'] = wtp_thresholds_list
        st.session_state.ceac['extracted_probabilities'] = extracted_probabilities
        st.session_state.ceac['wtp_thresholds'] = wtp_thresholds
        st.session_state.ceac['normalized_ceac_values_per_wtp'] = normalized_ceac_values_per_wtp

    else:
        extracted_probabilities =  st.session_state.ceac['extracted_probabilities']
        wtp = 10
        # ë¯¸ë””ì–´ë³„ë¡œ ë…¸ë©€ë¼ì´ì¦ˆëœ CEAC ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        for i, media in enumerate(st.session_state.ceac['icer_values'].keys()):
            wtp_index = st.session_state.ceac['wtp_thresholds_list'].index(wtp)
            plt.plot(st.session_state.ceac['wtp_thresholds'], st.session_state.ceac['normalized_ceac_values_per_wtp'][i], label=f'{media} (Normalized CEAC)')


        # Customize plot with additional information
        plt.title('CE Acceptability Curve')
        plt.xlabel('Willingness-to-Pay')
        plt.ylabel('% Iterations Cost-Effective')
        plt.legend(title="Strategy", loc='best', bbox_to_anchor=(1.05, 1))
        plt.grid(True)

        plt.tight_layout()
        st.pyplot(plt)

    st.write(
        '''
        - Willingness-To-Pay(WTP) ëŠ” ICER ê°’ìœ¼ë¡œ í•´ì„í•©ë‹ˆë‹¤. ê´‘ê³ íš¨ìœ¨ 1ì„ ì˜¬ë¦¬ê¸° ìœ„í•œ ì§€ë¶ˆ ë¹„ìš©ì…ë‹ˆë‹¤.
        - WTPì— ë”°ë¥¸ ë§¤ì²´ë³„ ë¯¹ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        '''
    )
    
    st.header("4. ì˜ˆì‚° ë¯¹ìŠ¤ ì¶”ì²œ")

    # ì…ë ¥ ë°ì´í„°: ì±„ë„ë³„ ë°ì´í„° (ì˜ˆì‹œ)
    df_rec = df_final

    df_probabilities = pd.DataFrame.from_dict(extracted_probabilities, orient='index')
    # Rename the columns to reflect the WTP values
    df_probabilities.columns = ['CEAC']

    # Reset the index so that media names become a column
    df_probabilities.reset_index(inplace=True)
    df_probabilities.rename(columns={'index': 'ë§¤ì²´'}, inplace=True)

    df_merged = pd.merge(df_rec, df_probabilities, on='ë§¤ì²´', how='left')
    df_merged['CEAC'] = df_merged['CEAC'].replace(0, 1e-2).fillna(1e-2)

    #st.write(df_merged)

    # ì´ ì˜ˆì‚° ì„¤ì •
    total_budget = st.text_input("ì˜ˆì‚°ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",41000000)
    if total_budget:
        total_budget = int(total_budget)
        # ëª©í‘œ í•¨ìˆ˜: ë§¤ì¶œì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì‚° í• ë‹¹ ìµœì í™”
        # ì˜ˆì‚° í• ë‹¹ ë¹„ìœ¨ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ICERì™€ CEACë¥¼ ë°˜ì˜
        df_merged['revenue_per_budget'] = df_merged['ë§¤ì¶œ'] / df_merged['ëˆ„ì ë¹„ìš©']

        # ëª©ì  í•¨ìˆ˜: ìµœëŒ€í™”í•  ê°’ (ë§ˆì´ë„ˆìŠ¤ë¥¼ ì·¨í•´ ìµœì†Œí™” ë¬¸ì œë¡œ ë³€í™˜)
        c = (-1*df_merged['revenue_per_budget'] * df_merged['CEAC'] * df_merged["ë§¤ì¶œ ë¹„ì¤‘"]).to_list()
        #st.write(df_merged['CEAC'], df_merged['revenue_per_budget'], c)

        # ì œì•½ ì¡°ê±´: ì˜ˆì‚°ì˜ í•©ì´ total_budgetì„ ë„˜ì§€ ì•Šê²Œ
        A = [1] * len(df_merged)  # ê° ì±„ë„ì˜ ì˜ˆì‚° ë¹„ìœ¨ í•©ì´ ì´ ì˜ˆì‚°ê³¼ ê°™ì•„ì•¼ í•¨
        b = [total_budget]
        
        if total_budget <= 53300000:
            upper_cap = 1.3
        else:
            upper_cap = math.ceil(total_budget*10/41000000) / 10
        # ê²½ê³„ ì¡°ê±´: ê° ì±„ë„ì˜ ì˜ˆì‚°ì€ 0 ì´ìƒì´ì–´ì•¼ í•˜ê³ , í˜„ì¬ ì˜ˆì‚° ì´ìƒìœ¼ë¡œëŠ” ì¦ê°€í•˜ì§€ ì•ŠìŒ
        bounds = [(0, budget*upper_cap) for budget in df_merged['ëˆ„ì ë¹„ìš©']]
        
        #st.write(c,A,b,bounds)

        # ì„ í˜• ê³„íšë²•ìœ¼ë¡œ ìµœì í™” ì‹¤í–‰
        result = linprog(c, A_eq=[A], b_eq=b, bounds=bounds, method='highs')

        # ìµœì í™”ëœ ì˜ˆì‚° í• ë‹¹ ê²°ê³¼
        df_merged['ì¶”ì²œ ì˜ˆì‚°'] = (result.x).round(0)
        df_merged['ê¸°ëŒ€ ë§¤ì¶œ'] = (df_merged['ì¶”ì²œ ì˜ˆì‚°'] * df_merged['revenue_per_budget']).round(0)
        df_merged.loc['í•©ê³„'] = df_merged.sum()

        # ê²°ê³¼ ì¶œë ¥
        st.write("ìµœì í™”ëœ ì˜ˆì‚° í• ë‹¹ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.")
        st.write(df_merged[['ë§¤ì²´', 'ëˆ„ì ë¹„ìš©','ë§¤ì¶œ', 'ì¶”ì²œ ì˜ˆì‚°', 'ê¸°ëŒ€ ë§¤ì¶œ']])
